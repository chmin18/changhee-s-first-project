{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabb2a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e190d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sio.loadmat('traindata.mat')\n",
    "images = (arr['I'])\n",
    "images2=[]\n",
    "for image in images:\n",
    "    images2.append([image])\n",
    "images2 = np.array(images2)\n",
    "images2 = torch.FloatTensor(images2)\n",
    "labels = torch.FloatTensor(arr['label'][0])\n",
    "data = [images2, labels]\n",
    "loader = [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180be633",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=200, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b58a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_modified(nn.Module):\n",
    "  def __init__(self,size):\n",
    "    super(CNN_modified, self).__init__()\n",
    "    # Construct convolutional layer    \n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5))\n",
    "    # num of input channel = 1, num of output channel 32, kernel size = 5×5 \n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Max-pooling with kernel size = 2×2, stride = 2\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5)\n",
    "    # num of input channel = 1, num of output channel 32, kernel size = 5×5 (5 = 5×5)    \n",
    "    self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "    # fc 쓰는 게 맞나??\n",
    "    self.fc1 = nn.Linear(in_features=size, out_features=256)\n",
    "    self.fc2 = nn.Linear(in_features=256, out_features=1) # The output size of last FC layer must be equal to num of class\n",
    "\n",
    "  def forward(self, x):\n",
    "    batchsize = x.size(0)\n",
    "    print('batchsize= ',batchsize)\n",
    "    x = self.conv1(x) # output for feature visuallization\n",
    "    x = self.pool1(F.relu(x)) # Convolutional layer -> ReLU activation -> max_pooling\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool2(F.relu(x))\n",
    "    x = self.conv3(x)\n",
    "    x = self.pool1(F.relu(x))\n",
    "    print(x.shape)\n",
    "    x = x.view(batchsize,-1) # Change the shape of output from [batch_size, channels, height, width] to [batch_size, channels*height*width]\n",
    "    x = F.relu(self.fc1(x))\n",
    "    out = self.fc2(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846cf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    # Construct convolutional layer    \n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5))\n",
    "    # num of input channel = 1, num of output channel 32, kernel size = 5×5 \n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Max-pooling with kernel size = 2×2, stride = 2\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5)\n",
    "    # num of input channel = 1, num of output channel 32, kernel size = 5×5 (5 = 5×5)    \n",
    "    \n",
    "    self.fc1 = nn.Linear(in_features=512, out_features=128)\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=10) # The output size of last FC layer must be equal to num of class\n",
    "\n",
    "  def forward(self, x):\n",
    "    batchsize = x.size(0)\n",
    "    x = self.conv1(x) # output for feature visuallization\n",
    "    x = self.pool(F.relu(x)) # Convolutional layer -> ReLU activation -> max_pooling\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool(F.relu(x))\n",
    "    x = x.view(batchsize,-1) # Change the shape of output from [batch_size, channels, height, width] to [batch_size, channels*height*width]\n",
    "    x = F.relu(self.fc1(x))\n",
    "    out = self.fc2(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146d4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epoch, loader, optimizer, criterion, device=\"cpu\"):\n",
    "  model.train()\n",
    "  for epoch in tqdm(range(n_epoch)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "      images, labels = data\n",
    "      #print(images.size())\n",
    "      #print('images\\n',images)\n",
    "      #print('labels\\n',labels)\n",
    "      images = images.to(device)\n",
    "      #print('images.todevice',images)\n",
    "      labels = labels.to(device)\n",
    "      #print('labels.todevice',labels)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(input=outputs, target=labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "    print('Epoch {}, loss = {:.3f}'.format(epoch, running_loss/len(loader)))\n",
    "  print('Training Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c54add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_modified(model, n_epoch, loader, optimizer, criterion, device=\"cpu\"):\n",
    "  model.train()\n",
    "  for epoch in tqdm(range(n_epoch)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "      images, labels = data\n",
    "      labels = labels.type(torch.LongTensor)\n",
    "      print(images.size())\n",
    "      #print('images\\n',images)\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(input=outputs, target=labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "    print('Epoch {}, loss = {:.3f}'.format(epoch, running_loss/len(loader)))\n",
    "  print('Training Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4a6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "  model.eval()\n",
    "  total=0\n",
    "  correct=0\n",
    "  with torch.no_grad():\n",
    "    for data in loader:\n",
    "      images, labels = data\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "    \n",
    "  acc = 100*correct/total\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b20f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 1, 400, 42])\n",
      "batchsize=  42\n",
      "torch.Size([42, 64, 46, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(params\u001b[38;5;241m=\u001b[39mcnn_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m) \u001b[38;5;66;03m#Ir 0.001 -> 0.01로 수정.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_modified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#train(model=cnn_model, n_epoch=15, loader=trainloader, optimizer=optimizer, criterion=criterion, device=\"cuda\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m acc \u001b[38;5;241m=\u001b[39m evaluate(cnn_model, testloader, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mtrain_modified\u001b[1;34m(model, n_epoch, loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39moutputs, target\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#PYTORCH_CUDA_ALLOC_CONF=5000 #max_split_size_mb\n",
    "cnn_model = CNN_modified(2944).to(\"cuda\")\n",
    "optimizer = optim.SGD(params=cnn_model.parameters(), lr=0.01, momentum=0.9) #Ir 0.001 -> 0.01로 수정.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_modified(model=cnn_model, n_epoch=1, loader=loader, optimizer=optimizer, criterion=criterion, device=\"cuda\")\n",
    "#train(model=cnn_model, n_epoch=15, loader=trainloader, optimizer=optimizer, criterion=criterion, device=\"cuda\")\n",
    "acc = evaluate(cnn_model, testloader, device=\"cuda\")\n",
    "print('Test accuracy: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b73ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
